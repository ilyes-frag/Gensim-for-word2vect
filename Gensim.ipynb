{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/ilyes-frag/Gensim-for-word2vect/blob/main/Gensim.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
      ],
      "metadata": {
        "id": "8IuBBo8e_NMs"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "#***1-Import Libraries and dependencies***"
      ],
      "metadata": {
        "id": "Ffy6s-pBw4wC"
      }
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Vv5q_zcIL3c1",
        "outputId": "1ae69224-443d-40e7-c58c-31efc6c0f803"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: gensim in /usr/local/lib/python3.10/dist-packages (4.3.2)\n",
            "Requirement already satisfied: numpy>=1.18.5 in /usr/local/lib/python3.10/dist-packages (from gensim) (1.23.5)\n",
            "Requirement already satisfied: scipy>=1.7.0 in /usr/local/lib/python3.10/dist-packages (from gensim) (1.11.4)\n",
            "Requirement already satisfied: smart-open>=1.8.1 in /usr/local/lib/python3.10/dist-packages (from gensim) (6.4.0)\n",
            "Collecting gender_guesser\n",
            "  Downloading gender_guesser-0.4.0-py2.py3-none-any.whl (379 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m379.3/379.3 kB\u001b[0m \u001b[31m6.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hInstalling collected packages: gender_guesser\n",
            "Successfully installed gender_guesser-0.4.0\n",
            "Requirement already satisfied: xlrd in /usr/local/lib/python3.10/dist-packages (2.0.1)\n",
            "Requirement already satisfied: openpyxl in /usr/local/lib/python3.10/dist-packages (3.1.2)\n",
            "Requirement already satisfied: et-xmlfile in /usr/local/lib/python3.10/dist-packages (from openpyxl) (1.1.0)\n"
          ]
        }
      ],
      "source": [
        "! pip install --upgrade gensim\n",
        "!pip install gender_guesser\n",
        "!pip install xlrd\n",
        "!pip install openpyxl"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import gensim\n",
        "import gensim.downloader\n",
        "import re\n",
        "import pandas as pd\n",
        "import gender_guesser.detector as gender"
      ],
      "metadata": {
        "id": "A3xmCAZ4MZtJ"
      },
      "execution_count": 3,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "'''\n",
        "from google.colab import drive\n",
        "import gensim.downloader\n",
        "\n",
        "# Mount Google Drive\n",
        "drive.mount('/content/drive')\n",
        "\n",
        "# Set the directory path in Google Drive\n",
        "DRIVE_DIR = '/content/drive/MyDrive'\n",
        "\n",
        "# Set the base directory for gensim downloader\n",
        "gensim.downloader.BASE_DIR = DRIVE_DIR\n",
        "'''\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 53
        },
        "id": "QQ-jcA9Ff-Gu",
        "outputId": "5da5ef8c-65a9-4a5f-a20d-370592804f58"
      },
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "\"\\nfrom google.colab import drive\\nimport gensim.downloader\\n\\n# Mount Google Drive\\ndrive.mount('/content/drive')\\n\\n# Set the directory path in Google Drive\\nDRIVE_DIR = '/content/drive/MyDrive'\\n\\n# Set the base directory for gensim downloader\\ngensim.downloader.BASE_DIR = DRIVE_DIR\\n\""
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            }
          },
          "metadata": {},
          "execution_count": 4
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "google_news_vectors = gensim.downloader.load('word2vec-google-news-300')\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "jOD5wOf2MfVs",
        "outputId": "303a9439-1c2b-430c-d925-69652c30a4db"
      },
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[==================================================] 100.0% 1662.8/1662.8MB downloaded\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "#***2-Knowing that the capital of Paris is France, use vector reasoning to find the capital of Germany and the capital of Australia and explain the answers***\n",
        "\n",
        "for Germany i got the correct answer since i think Berlin is famous but the word vector model associating \"Australia\" with \"Sydney\" because \"Sydney\" appears frequently in contexts related to Australia"
      ],
      "metadata": {
        "id": "FVB5YSZPxFfo"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "print(google_news_vectors.most_similar(positive=['Germany','Paris'], negative=['France'], topn=1))\n",
        "print(google_news_vectors.most_similar(positive=['Australia','Paris'], negative=['France'], topn=1))\n",
        "\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Tv8lzSLXQzix",
        "outputId": "8d7280b0-5fea-452c-ae52-8438afb74434"
      },
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[('Berlin', 0.7644002437591553)]\n",
            "[('Sydney', 0.7721031308174133)]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "#***3-By considering the USA and by considering Russia, use vector reasoning to find the UK Prime Minister from the corpus and explain the answers you get.***"
      ],
      "metadata": {
        "id": "Bfwta7Pj0NsA"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "print(google_news_vectors.most_similar(positive=['Prime_Minister','Putin'], negative=['Obama'], topn=10))\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Zsq6rR_KxLVY",
        "outputId": "4863462b-9cb0-40c8-f5eb-f2386cae9362"
      },
      "execution_count": 30,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[('Prime_Minster', 0.665986955165863), ('prime_minister', 0.6513209342956543), ('Deputy_Prime_Minister', 0.621185839176178), ('Prime_Minsiter', 0.61000657081604), ('Vladimir_Putin', 0.6062374711036682), ('President_Vladimir_Putin', 0.5851495265960693), ('Prime_Ministers', 0.5806546211242676), ('Prime_MInister', 0.5777046084403992), ('PrimeMinister', 0.5774396061897278), ('Prime_Mininster', 0.5735327005386353)]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "#***4-What are the 5 most similar words to the word BMW?***"
      ],
      "metadata": {
        "id": "ICYUcg250Xeg"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "similar_words = google_news_vectors.similar_by_word(\"BMW\", topn=5)\n",
        "\n",
        "print(\"The 5 most similar words to 'BMW' are:\")\n",
        "for word, similarity in similar_words:\n",
        "    print(f\"{word}: {similarity}\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "93DdxPY3gylv",
        "outputId": "545d9967-6ac8-4822-c5c7-e1a060b11d7e"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "The 5 most similar words to 'BMW' are:\n",
            "Audi: 0.7932199835777283\n",
            "Mercedes_Benz: 0.7683466672897339\n",
            "Porsche: 0.7272197604179382\n",
            "Mercedes: 0.7078384160995483\n",
            "Volkswagen: 0.6959410905838013\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "the words \"Audi\", \"Mercedes_Benz\", \"Porsche\", \"Mercedes\", and \"Volkswagen\" are returned because they frequently appear in similar contexts to \"BMW\" in the training data. These words are often mentioned together with \"BMW\" in discussions about the automotive industry."
      ],
      "metadata": {
        "id": "04e2imyb1Tt9"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "#***5-What are the 5 most similar words to the word Tesla***"
      ],
      "metadata": {
        "id": "kbzZwiyat_3X"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "similar_words = google_news_vectors.similar_by_word(\"Tesla\", topn=5)\n",
        "print(\"The 5 most similar words  to 'Tesla' are:\\n\")\n",
        "for word, similarity in similar_words:\n",
        "    print(f\"* {word} : {similarity}\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Q_i6-H3IqOVD",
        "outputId": "655098f7-32d4-4549-cc16-e3a2ba69355b"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "The 5 most similar words  to 'Tesla' are:\n",
            "\n",
            "* Tesla_Motors : 0.720951497554779\n",
            "* Tesla_Roadster : 0.6531893014907837\n",
            "* afford_Nummi_Musk : 0.65052330493927\n",
            "* Telsa : 0.6308883428573608\n",
            "* electric_Tesla_Roadster : 0.6106851696968079\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Overall, the results reflect various aspects of Tesla, including the company name, specific models, related terms, and potential misspellings or variations"
      ],
      "metadata": {
        "id": "ZX9ZanbSuXoy"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "#***6-Which of the words battle and love are closest to the word fight***"
      ],
      "metadata": {
        "id": "hbnkFT3wuZYG"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "battle_fights=[]\n",
        "words=[\"battle\",\"love\"]\n",
        "for word in words:\n",
        "  battle_fight=google_news_vectors.similarity(word,\"fight\")\n",
        "  battle_fights.append(tuple((battle_fight,word)))\n",
        "result=max(battle_fights)\n",
        "print(\"the closest word to the word 'fight' is : \",result[1],\"\\nwith score :\",result[0])\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "3Ljksv5OsaOL",
        "outputId": "ffa333be-a4ee-467d-cc02-32b90b185905"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "the closest word to the word 'fight' is :  battle \n",
            "with score : 0.7021284\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "The code calculates the similarity between the word \"fight\" and each word in the list [\"battle\", \"love\"] using the Word2Vec model.\n",
        "\n",
        "It stores the similarity scores and corresponding words in a list of tuples named battle_fights.\n",
        "\n",
        "Then, it finds the word with the highest similarity score using the max() function.\n",
        "\n",
        "Finally, it prints the word with the highest similarity score along with the corresponding similarity score."
      ],
      "metadata": {
        "id": "6lom9Dx8vf9f"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "#***7-Exploring Gender Bias in Scientist Representation***\n"
      ],
      "metadata": {
        "id": "3cD4XVR20jb-"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "result=google_news_vectors.most_similar(positive=['Albert_Einstein'], topn=100)\n",
        "print(result)\n",
        "for name in result:\n",
        "  print(name[0])\n",
        "\n"
      ],
      "metadata": {
        "id": "DcSPWOqXABkh"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "reg='^(\\w+)\\_(\\w+)(\\w+)'\n",
        "male=[]\n",
        "female=[]\n",
        "for name in result:\n",
        "  match=re.search(reg,name[0])\n",
        "  if match:\n",
        "    #print(name)\n",
        "    #print(match.group(1))\n",
        "    first_name=match.group(1)\n",
        "    gd = gender.Detector()\n",
        "    names_gender=gd.get_gender(first_name)\n",
        "    #print(names_gender)\n",
        "    if names_gender == 'male':\n",
        "      male.append(names_gender)\n",
        "    elif names_gender == 'female' :\n",
        "      female.append(names_gender)\n",
        "\n",
        "print('Number of scientifics Male :',len(male))\n",
        "print('Number of scientifics Female :',len(female))\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Oz68OEZFGejd",
        "outputId": "f94f1258-caca-452d-f0c7-752c10e349b7"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Number of scientifics Male : 46\n",
            "Number of scientifics Female : 3\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "\n",
        "\n",
        "\n",
        "###**Analysis:**\n",
        "\n",
        "\n",
        "*In this example, we examine the representation of male and female scientists in our corpus. We observe that the number of male scientists mentioned is higher than that of female scientists, indicating a potential gender bias in the dataset.*\n",
        "\n",
        "\n",
        "###**Addressing Gender Bias:**\n",
        "\n",
        "**1. Retraining Approaches:**\n",
        "\n",
        "***Data Augmentation:***\n",
        " Increase the diversity of the dataset by augmenting data with balanced representation of male and female scientists.\n",
        "\n",
        "***Bias-Aware Objective Function:***\n",
        " Train models with objective functions that penalize gender bias, ensuring fair representation.\n",
        "\n",
        "**2. Word Embedding:**\n",
        "\n",
        "Define the Linear Guarding Function: Utilize methods such as debiasing algorithms to remove gender bias from word embeddings, ensuring more equitable representation.\n",
        "\n",
        "*Resources:*\n",
        "\n",
        " related video on YouTube: https://www.youtube.com/watch?v=4kAMXWkF62c"
      ],
      "metadata": {
        "id": "Yma02Oq2wwe-"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "#***8-How is a word vector represented as a Python data structure***\n",
        "\n",
        "In Python, a word vector is commonly represented as a numerical array. Think of it as a list of numbers, where each number represents a different aspect or characteristic of the word. These numbers are determined by the vector space model"
      ],
      "metadata": {
        "id": "wO3qbWhiwFRu"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "dog = google_news_vectors['kingdom']\n",
        "print(dog.shape)\n",
        "print(dog[:10])"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "3jUxcxO5GbHt",
        "outputId": "cf9e6e1e-b57b-4a78-c8cb-003ab05254b5"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "(300,)\n",
            "[ 0.13378906 -0.0859375  -0.24609375 -0.18164062 -0.03710938  0.09130859\n",
            "  0.12597656 -0.33203125 -0.12792969  0.29101562]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "#***9-Which of these words is the odd one out? California Texas Alaska India***"
      ],
      "metadata": {
        "id": "IeY7cN22wlIV"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "print('the odd word out is :',google_news_vectors.doesnt_match(['California', 'Texas', 'Alaska', 'India']))\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Bk_m5VBavx8D",
        "outputId": "8a83770a-78fc-4d70-8b9f-b60db02510ed"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "the odd word out is : India\n"
          ]
        }
      ]
    }
  ]
}
